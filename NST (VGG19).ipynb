{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2f3d56",
   "metadata": {},
   "source": [
    "# Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90c61e",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as img\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a921e",
   "metadata": {},
   "source": [
    "## Using a pre-trained VGG19 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 400\n",
    "vgg19 = tf.keras.applications.VGG19(include_top=False,\n",
    "                                        weights=\"Imagenet_weights\\o\",\n",
    "                                        input_shape=(img_size, img_size, 3))\n",
    "vgg19.trainable = False\n",
    "print(vgg19.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385026a0",
   "metadata": {},
   "source": [
    "## Displaying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = img.open(\"Pictures\\Content\\Bridge.jpg\")\n",
    "print(\"Content's Image\")\n",
    "content_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07204f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "style_image = img.open(\"Pictures\\Style\\Impressionism\\Starry night.jpg\")\n",
    "print(\"Style's Image\")\n",
    "style_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45f5db",
   "metadata": {},
   "source": [
    "## Content Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_cost(content_output, generated_output):\n",
    "    c = content_output[-1]\n",
    "    g = generated_output[-1]\n",
    "    m, n_h, n_w, n_c = g.get_shape().as_list()\n",
    "    c_unrolled = tf.reshape(c, shape=[m, n_h * n_w, n_c])\n",
    "    g_unrolled = tf.reshape(g, shape=[m, n_h * n_w, n_c])\n",
    "    j_content = (1 / (4 * n_h * n_w * n_c)) * tf.reduce_sum(tf.square(tf.subtract(c, g)))\n",
    "    return j_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9549c5",
   "metadata": {},
   "source": [
    "## Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    gram = tf.matmul(x, tf.transpose(x))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25014306",
   "metadata": {},
   "source": [
    "## Style Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c83ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_cost_layer(s, g):\n",
    "    m, n_h, n_w, n_c = g.get_shape().as_list()\n",
    "    s = tf.transpose(tf.reshape(s, shape=[-1, n_c]))\n",
    "    g = tf.transpose(tf.reshape(g, shape=[-1, n_c]))\n",
    "    gs = gram_matrix(s)\n",
    "    gg = gram_matrix(g)\n",
    "    j_style = tf.reduce_sum(tf.square(gs - gg)) / (4.0 *(( n_h * n_w * n_c) ** 2))\n",
    "    return j_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8815f",
   "metadata": {},
   "source": [
    "## Retrieve a layer's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f57f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19.get_layer('block5_conv4').output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ebc1e",
   "metadata": {},
   "source": [
    "## Define Style Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1445b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = [\n",
    "    ('block1_conv1', 0.2),\n",
    "    ('block2_conv1', 0.2),\n",
    "    ('block3_conv1', 0.2),\n",
    "    ('block4_conv1', 0.2),\n",
    "    ('block5_conv1', 0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5dcd0",
   "metadata": {},
   "source": [
    "## Compute style cost for several layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ba050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_cost(style_img_out, generated_img_out, sl = style_layers):\n",
    "    j_style = 0\n",
    "    s = style_img_out[:-1]\n",
    "    g = generated_img_out[:-1]\n",
    "    for i, weight in zip(range(len(s)), sl):\n",
    "        j_style_layer = style_cost_layer(s[i], g[i])\n",
    "        j_style += weight[1] * j_style_layer\n",
    "    return j_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e156264",
   "metadata": {},
   "source": [
    "## Total Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e342be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def total_cost(j_content, j_style, alpha = 10, beta = 40):\n",
    "    J = alpha * j_content + beta * j_style\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25103eab",
   "metadata": {},
   "source": [
    "## Load the content image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = np.array(img.open(\"Pictures\\Content\\Bridge.jpg\").resize((img_size, img_size)))\n",
    "content_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n",
    "print(content_image.shape)\n",
    "plt.imshow(content_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b605cc",
   "metadata": {},
   "source": [
    "## Load the style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40429688",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image =  np.array(img.open(\"Pictures\\Style\\Impressionism\\Starry night.jpg\").resize((img_size, img_size)))\n",
    "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
    "\n",
    "print(style_image.shape)\n",
    "plt.imshow(style_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a9251",
   "metadata": {},
   "source": [
    "## Random initialization of the generated image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff532f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "noise = tf.random.uniform(tf.shape(generated_image), -0.25, 0.25)\n",
    "generated_image = tf.add(generated_image, noise)\n",
    "generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "print(generated_image.shape)\n",
    "plt.imshow(generated_image.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f91e7",
   "metadata": {},
   "source": [
    "## Load pre-trained VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18239c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_outputs(vgg19, layer_names):\n",
    "    outputs = [vgg19.get_layer(layer[0]).output for layer in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg19.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab436a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = [('block5_conv4', 1)]\n",
    "\n",
    "vgg19_model_outputs = layer_outputs(vgg19, style_layers + content_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_target = vgg19_model_outputs(content_image)\n",
    "style_target = vgg19_model_outputs(style_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a82baa",
   "metadata": {},
   "source": [
    "## Compute the content image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "c = vgg19_model_outputs(preprocessed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808e379",
   "metadata": {},
   "source": [
    "## Compute the Style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
    "s = vgg19_model_outputs(preprocessed_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99423199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor * 255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor) > 3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return img.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e90dc",
   "metadata": {},
   "source": [
    "## Compile step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504287dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function()\n",
    "def train_step(generated_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        g = vgg19_model_outputs(generated_image)\n",
    "        j_style = style_cost(s, g)\n",
    "        j_content = content_cost(c, g)\n",
    "        J = total_cost(j_content, j_style, 10, 40)\n",
    "    grad = tape.gradient(J, generated_image)\n",
    "    optimizer.apply_gradients([(grad, generated_image)])\n",
    "    generated_image.assign(clip_0_1(generated_image))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(generated_image)\n",
    "\n",
    "J1 = train_step(generated_image)\n",
    "print(J1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caceaf7e",
   "metadata": {},
   "source": [
    "## Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10001\n",
    "for i in range(epochs):\n",
    "    train_step(generated_image)\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Epoch {i} \")\n",
    "    if i % 500 == 0:\n",
    "        image = tensor_to_image(generated_image)\n",
    "        plt.imshow(image)\n",
    "        image.save(f\"Pictures\\Output/image_{i}.jpg\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35688f7f",
   "metadata": {},
   "source": [
    "## Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3556d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(content_image[0])\n",
    "ax.title.set_text('Content image')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(style_image[0])\n",
    "ax.title.set_text('Style image')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(generated_image[0])\n",
    "ax.title.set_text('Generated image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07c842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
